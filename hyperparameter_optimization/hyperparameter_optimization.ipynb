{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bd3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tqdm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap,grad\n",
    "from functools import partial\n",
    "from jax.example_libraries import stax\n",
    "from jax.example_libraries.stax import Dense,Relu,Flatten,Sigmoid\n",
    "from jax import jit\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.tree_util import tree_multimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a6e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=jax.random.PRNGKey(1)\n",
    "num_task_sample=5\n",
    "ethnic_grp_min_pop=60 #min population among all subpopulatiosn\n",
    "reg_weight=0.1\n",
    "lr=0.001\n",
    "\n",
    "def linear_model(eth, x):\n",
    "    # dictionary which contains randomly generated coefficnets for the linear model\n",
    "    eth_coef = {}\n",
    "    eth_errors = {}\n",
    "    eth_errors_sigma2 = np.random.randint(1, 5, size=len(eth))\n",
    "    eth_errors.update([(ethnicity, errors / 100) for ethnicity, errors in zip(eth, eth_errors_sigma2)])\n",
    "\n",
    "    for i in eth:\n",
    "        eth_coef[i] = np.random.uniform(-1, 1, (x.shape[1]))\n",
    "\n",
    "    y = x.apply(lambda a: a @ eth_coef[a.name[0]] + np.random.normal(scale=eth_errors[a.name[0]]), axis=1)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def hetero_model(eth, x, max_threshold=20, num_heteromodel_causal_snps=10):\n",
    "    threshold_vec = np.random.randint(max_threshold,\n",
    "                                      size=len(eth))  # random choice of thresholds as many as ethnicities\n",
    "    heteromodel_causal_snps = np.random.choice(x.columns, size=num_heteromodel_causal_snps,\n",
    "                                               replace=False)  # choose 10 causal snps from columns of x\n",
    "    heteromodel_coef = []  # array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh = {}  # dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps:\n",
    "            heteromodel_coef.append(1)\n",
    "        else:\n",
    "            heteromodel_coef.append(0)\n",
    "\n",
    "    j = 0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh[i] = threshold_vec[j]\n",
    "        j = j + 1\n",
    "\n",
    "    y = x.apply(lambda t: 1 if t @ heteromodel_coef > heteromodel_thresh[t.name[0]] else 0, axis=1)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def compensatory_model(eth, x, max_threshold1=10, max_threshold2=5, num_heteromodel_causal_snps1=20,\n",
    "                       num_heteromodel_causal_snps2=50):\n",
    "    threshold_vec1 = np.random.randint(max_threshold1,\n",
    "                                       size=len(eth))  # random choice of thresholds as many as ethnicities\n",
    "    threshold_vec2 = np.random.randint(max_threshold2,\n",
    "                                       size=len(eth))  # random choice of thresholds as many as ethnicities\n",
    "\n",
    "    heteromodel_causal_snps = np.random.choice(x.columns,\n",
    "                                               size=num_heteromodel_causal_snps1 + num_heteromodel_causal_snps2,\n",
    "                                               replace=False)  # choose 10 causal snps from columns of x\n",
    "    heteromodel_causal_snps1 = heteromodel_causal_snps[0:num_heteromodel_causal_snps1]\n",
    "    heteromodel_causal_snps2 = heteromodel_causal_snps[num_heteromodel_causal_snps1:-1]\n",
    "    heteromodel_coef1 = []  # array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh1 = {}  # dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps1:\n",
    "            heteromodel_coef1.append(1)\n",
    "        else:\n",
    "            heteromodel_coef1.append(0)\n",
    "\n",
    "    j = 0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh1[i] = threshold_vec1[j]\n",
    "        j = j + 1\n",
    "\n",
    "    heteromodel_coef2 = []  # array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh2 = {}  # dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps2:\n",
    "            heteromodel_coef2.append(1)\n",
    "        else:\n",
    "            heteromodel_coef2.append(0)\n",
    "\n",
    "    j = 0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh2[i] = threshold_vec2[j]\n",
    "        j = j + 1\n",
    "\n",
    "    y = x.apply(lambda t: 0 if (((t @ heteromodel_coef1 > heteromodel_thresh1[t.name[0]]) and\n",
    "                                 (t @ heteromodel_coef2 > heteromodel_thresh2[t.name[0]])) |\n",
    "                                ((t @ heteromodel_coef1 <= heteromodel_thresh1[t.name[0]]) and\n",
    "                                 (t @ heteromodel_coef2 <= heteromodel_thresh2[t.name[0]])))\n",
    "    else 1, axis=1)\n",
    "\n",
    "    # return heteromodel_thresh1,heteromodel_thresh2,y\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e776660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('processed_data.csv',index_col=[0,1])\n",
    "eth_ID=pd.read_csv('eth_ID.csv',index_col=0)\n",
    "eth=eth_ID['eth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9da4b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maml_logistic_model(eth_train, x_train, y_train, x_test, y_test,epochs=20000,batch_size=20,num_task_sample= 5,reg_weight=reg_weight):\n",
    "    # define model\n",
    "    num_features=x_train.shape[1]\n",
    "    in_shape=(-1,num_features)\n",
    "    net_init, net_apply = stax.serial(Dense(1),Sigmoid)\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size=lr)\n",
    "    out_shape, net_params = net_init(rng, in_shape)\n",
    "    opt_state = opt_init(net_params)\n",
    "\n",
    "    # auxilliary functions\n",
    "    def binary_cross_entropy(y_hat, y):\n",
    "        bce = y * jnp.log(y_hat) + (1 - y) * jnp.log(1 - y_hat)\n",
    "        return jnp.mean(-bce)\n",
    "\n",
    "    def loss(params, inputs, targets):\n",
    "        predictions = net_apply(params, inputs)\n",
    "        #print(binary_cross_entropy(predictions,targets),jnp.linalg.norm(net_params[0], 1))\n",
    "        return binary_cross_entropy(predictions,targets)+reg_weight * jnp.linalg.norm(net_params[0][0], 1)\n",
    "\n",
    "    def accuracy(params, inputs, targets):\n",
    "        predictions = net_apply(params, inputs)\n",
    "        return jnp.mean((predictions >= 1/2) == (targets >= 1/2))\n",
    "\n",
    "    def inner_update(p, x1, y1):\n",
    "        grads = grad(loss)(p, x1, y1)\n",
    "        inner_sgd_fn = lambda g, state: (state - lr * g)\n",
    "        return tree_multimap(inner_sgd_fn,grads,p)\n",
    "        #return [(w - lr * dw) for w, dw in zip(p, grads)]\n",
    "\n",
    "    def maml_loss(p, x1, y1, x2, y2):\n",
    "        p2 = inner_update(p, x1, y1)\n",
    "        return loss(p2, x2, y2)\n",
    "\n",
    "    # vmapped version of maml loss.\n",
    "    # returns scalar for all tasks.\n",
    "    def batch_maml_loss(p, x1_b, y1_b, x2_b, y2_b):\n",
    "        task_losses = vmap(partial(maml_loss, p))(x1_b, y1_b, x2_b, y2_b)\n",
    "        return jnp.mean(task_losses)\n",
    "\n",
    "    @jit\n",
    "    def step(i, opt_state, x1, y1, x2, y2):\n",
    "        p = get_params(opt_state)\n",
    "        g = grad(batch_maml_loss)(p, x1, y1, x2, y2)\n",
    "        l = batch_maml_loss(p, x1, y1, x2, y2)\n",
    "        return opt_update(i, g, opt_state), l\n",
    "\n",
    "    np_batched_maml_loss = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(epochs)):\n",
    "        x1_b, y1_b, x2_b, y2_b = sample_tasks(num_task_sample, batch_size, ethnic_grp_min_pop, eth_train, x_train,\n",
    "                                              y_train)\n",
    "        opt_state, l = step(i, opt_state, x1_b, y1_b, x2_b, y2_b)\n",
    "        np_batched_maml_loss.append(l)\n",
    "        #if i % 1000 == 0:\n",
    "        #    print(i, 'maml_loss', l)\n",
    "    net_params = get_params(opt_state)\n",
    "\n",
    "    # meta testing\n",
    "    # meta test; train with batch_size many examples from validation set on desired task\n",
    "\n",
    "    # pre update prediction\n",
    "    pre_predictions = vmap(partial(net_apply, net_params))(x_test)\n",
    "    pre_error = loss(net_params, x_test, y_test)\n",
    "    #print('pre update loss=' + str(pre_error))\n",
    "    # post-update prediction\n",
    "    indx = np.random.randint(x_test.shape[0], size=batch_size)\n",
    "    test_indx = np.delete(np.arange(x_test.shape[0]), indx)\n",
    "    x1, y1 = x_test[indx], y_test[indx]\n",
    "    for i in range(batch_size):\n",
    "        net_params = inner_update(net_params, x1, y1)\n",
    "        # print('training loss '+str(l))\n",
    "        # train_accuracy= accuracy(net_params,x1,y1)\n",
    "        # print('train accuracy',train_accuracy)\n",
    "        # post_error= loss(net_params,x_test[test_indx],y_test[test_indx])\n",
    "        # print('Post step ' + str(i)+' update test MSE='+str(post_error))\n",
    "\n",
    "    # post_predictions = vmap(partial(net_apply, net_params))(x_test)\n",
    "    logistic_maml_acc = accuracy(net_params, x_test[test_indx], y_test[test_indx])\n",
    "    #print('Test Accuracy on Task: MSE = ', logistic_maml_acc)\n",
    "\n",
    "    return np_batched_maml_loss, logistic_maml_acc\n",
    "\n",
    "\n",
    "def base_logistic_model(eth_train, x_train, y_train, x_test, y_test,epochs=20000,batch_size=20,reg_weight=reg_weight):\n",
    "    num_features = x_train.shape[1]\n",
    "    in_shape = (-1, num_features)\n",
    "\n",
    "    basenet_init, basenet_apply = stax.serial(Dense(1), Sigmoid)\n",
    "    out_shape, basenet_params = basenet_init(rng, input_shape=in_shape)\n",
    "    opt_init, opt_update, get_params = optimizers.adam(step_size=lr)\n",
    "    opt_state = opt_init(basenet_params)\n",
    "\n",
    "    @jit\n",
    "    def step(i, opt_state, x1, y1):\n",
    "        p = get_params(opt_state)\n",
    "        g = grad(batch_loss)(p, x1, y1)\n",
    "        l = batch_loss(p, x1, y1)\n",
    "        return opt_update(i, g, opt_state), l\n",
    "\n",
    "\n",
    "    def binary_cross_entropy(y_hat, y):\n",
    "        bce = y * jnp.log(y_hat) + (1 - y) * jnp.log(1 - y_hat)\n",
    "        \n",
    "        return jnp.mean(-bce)\n",
    "\n",
    "    def loss(params, inputs, targets):\n",
    "        predictions = basenet_apply(params, inputs)\n",
    "        bce=binary_cross_entropy(predictions, targets)\n",
    "        \n",
    "        return binary_cross_entropy(predictions, targets) + reg_weight * jnp.linalg.norm(basenet_params[0][0], 1)\n",
    "\n",
    "\n",
    "    def batch_loss(p,x1,y1):\n",
    "        task_losses = vmap(partial(loss, p))(x1, y1)\n",
    "        return jnp.mean(task_losses)\n",
    "\n",
    "    def accuracy(params, inputs, targets):\n",
    "        predictions = basenet_apply(params, inputs)\n",
    "        return jnp.mean((predictions >= 1/2) == (targets >= 1/2))\n",
    "\n",
    "    def update(p, x1, y1):\n",
    "        grads = grad(loss)(p, x1, y1)\n",
    "        inner_sgd_fn = lambda g, state: (state - lr * g)\n",
    "        return tree_multimap(inner_sgd_fn,grads,p)\n",
    "\n",
    "    np_batched_loss = []\n",
    "    for i in tqdm.tqdm(range(epochs)):\n",
    "        indices = np.random.randint(x_train.shape[0], size=batch_size * num_task_sample)\n",
    "        x1, y1 = x_train.iloc[indices].to_numpy(), y_train.iloc[indices].to_numpy()\n",
    "        opt_state, l = step(i, opt_state, x1, y1)\n",
    "        np_batched_loss.append(l)\n",
    "    basenet_params = get_params(opt_state)\n",
    "    #  if i % 1000 == 0:\n",
    "    #     train_loss = loss(basenet_params, x_train.to_numpy(), y_train.to_numpy())\n",
    "    #    print(i, 'training loss', train_loss)\n",
    "\n",
    "    indx = np.random.randint(x_test.shape[0], size=batch_size)\n",
    "    test_indx = np.delete(np.arange(x_test.shape[0]), indx)\n",
    "    x1, y1 = x_test[indx], y_test[indx]\n",
    "    for i in range(batch_size):\n",
    "        basenet_params = update(basenet_params, x1, y1)\n",
    "\n",
    "    logistic_test_acc = accuracy(basenet_params, x_test, y_test)\n",
    "\n",
    "    #print('test error accuracy', logistic_test_acc)\n",
    "    return np_batched_loss, logistic_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5449404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tasks(outer_batch_size, inner_batch_size,ethnic_grp_min_pop,eth_train,x_train,y_train):\n",
    "    # Select amplitude and phase for the task\n",
    "    ethnic_grp_sample=random.sample(list(eth_train), k=outer_batch_size)\n",
    "\n",
    "    def get_batch():\n",
    "        xs, ys = [], []\n",
    "        for j in ethnic_grp_sample:\n",
    "            indices = np.random.randint(ethnic_grp_min_pop,size=inner_batch_size)\n",
    "            x= x_train.loc[j].iloc[indices].to_numpy()\n",
    "            y= y_train.loc[j].iloc[indices].to_numpy()\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        return np.stack(xs), np.stack(ys)\n",
    "    x1, y1 = get_batch()\n",
    "    x2, y2 = get_batch()\n",
    "    return x1, y1, x2, y2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0b8d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5000\n",
    "batch_size=30 #inner batch size for inner loop#K=20 #K-shot learning\n",
    "num_task_sample= 4 #number of tasks to sample to meta train\n",
    "\n",
    "data1=pd.read_csv('processed_data.csv',index_col=[0,1])\n",
    "eth_ID=pd.read_csv('eth_ID.csv',index_col=[0])\n",
    "eth=eth_ID['eth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7127f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 916.92it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 115.79it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1037.19it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 117.03it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1056.82it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 114.23it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1009.78it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:44<00:00, 112.55it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1054.17it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.91it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1051.94it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:44<00:00, 111.42it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 995.50it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:44<00:00, 111.35it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 924.67it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.00it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 998.46it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 108.91it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1018.72it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 109.92it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 983.91it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 111.08it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1026.97it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 109.57it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1019.36it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:44<00:00, 112.09it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1172.86it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [06:33<00:00, 12.69it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1039.69it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:53<00:00, 93.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 0\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1046.03it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 117.65it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 999.95it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 118.92it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1043.41it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:53<00:00, 93.29it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 940.37it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:46<00:00, 108.16it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 975.98it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:46<00:00, 107.77it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 980.37it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:46<00:00, 108.35it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 956.58it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 109.29it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 985.65it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 109.82it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 969.64it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.20it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 981.88it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.17it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 901.13it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.55it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 978.74it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.44it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 986.86it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 109.31it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1128.15it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 125.79it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1154.06it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 123.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 1\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1097.38it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [01:10<00:00, 70.84it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:13<00:00, 362.90it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [26:57<00:00,  3.09it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:22<00:00, 217.55it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [19:14<00:00,  4.33it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:13<00:00, 366.59it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:38<00:00, 31.51it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 441.84it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:15<00:00, 36.85it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 491.47it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:08<00:00, 38.94it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 483.39it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [14:39<00:00,  5.69it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|███████████████████████████████████████| 5000/5000 [17:18<00:00,  4.82it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [34:02<00:00,  2.45it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 428.62it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:40<00:00, 31.21it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 440.33it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:20<00:00, 35.53it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 496.78it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:07<00:00, 39.15it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 471.87it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:23<00:00, 34.93it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 490.06it/s]\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:04:54<00:00,  1.28it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 400.12it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [44:45<00:00,  1.86it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 385.57it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:31<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 2\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 441.21it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:16<00:00, 36.63it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 495.20it/s]\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:22:43<00:00,  1.01it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|███████████████████████████████████████| 5000/5000 [15:41<00:00,  5.31it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:31<00:00, 32.97it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:13<00:00, 381.29it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:28<00:00, 33.56it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 430.60it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:13<00:00, 37.31it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 487.13it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:15<00:00, 36.96it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 439.23it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [27:17<00:00,  3.05it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 404.24it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [13:15<00:00,  6.29it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:13<00:00, 374.75it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [53:44<00:00,  1.55it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|███████████████████████████████████████| 5000/5000 [14:37<00:00,  5.70it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [17:34<00:00,  4.74it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:13<00:00, 368.78it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:46<00:00, 29.96it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 431.56it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:24<00:00, 34.52it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 414.55it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:16<00:00, 36.55it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 477.36it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:13<00:00, 37.46it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 436.36it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:24<00:00, 34.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 3\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 492.86it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:07<00:00, 39.12it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 471.67it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:25<00:00, 34.36it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 451.18it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:03<00:00, 40.37it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 504.65it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:19<00:00, 35.73it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 386.28it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:19<00:00, 35.72it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 497.63it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.04it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 524.67it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.05it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 520.17it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.09it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 498.86it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:13<00:00, 37.36it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 511.42it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.26it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 520.58it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:00<00:00, 41.50it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 527.21it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.30it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 512.48it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:00<00:00, 41.47it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 503.51it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:14<00:00, 37.28it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 505.18it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 4\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 510.85it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.06it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 498.42it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:02<00:00, 40.87it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 509.62it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:02<00:00, 40.96it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 509.21it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.00it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 490.54it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:15<00:00, 36.93it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 523.39it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.09it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 522.33it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:00<00:00, 41.46it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 525.90it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:00<00:00, 41.48it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 513.48it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:08<00:00, 38.86it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 467.71it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:05<00:00, 39.73it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 525.33it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:00<00:00, 41.33it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:26<00:00, 189.40it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:57<00:00, 28.21it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 394.50it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:41<00:00, 30.95it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:14<00:00, 355.78it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:48<00:00, 29.75it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 416.83it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:32<00:00, 32.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 5\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 424.22it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:28<00:00, 33.66it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 428.31it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:26<00:00, 34.04it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 434.92it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:17<00:00, 36.49it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 486.36it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:20<00:00, 35.47it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 429.10it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [49:03<00:00,  1.70it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:15<00:00, 318.13it/s]\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:30:41<00:00,  1.09s/it]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:12<00:00, 391.09it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:33<00:00, 32.47it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 431.25it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:15<00:00, 36.89it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 499.39it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:18<00:00, 36.19it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 438.04it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:25<00:00, 34.44it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:11<00:00, 426.96it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:07<00:00, 39.27it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 524.69it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.09it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 526.78it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.18it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 507.16it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:02<00:00, 40.71it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 517.12it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:02<00:00, 40.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 6\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 499.23it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.05it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 521.31it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:01<00:00, 41.04it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 509.13it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:02<00:00, 40.82it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 513.81it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:02<00:00, 40.79it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:09<00:00, 509.94it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [21:16<00:00,  3.92it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:08<00:00, 583.87it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:58<00:00, 85.90it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 933.54it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 115.19it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1180.21it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:44<00:00, 111.18it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1084.30it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:52<00:00, 95.09it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1120.40it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 117.14it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1131.75it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 121.88it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1161.30it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:51<00:00, 97.35it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1005.34it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.80it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1171.37it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 125.52it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1130.31it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 125.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 7\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 906.51it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 124.08it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1183.67it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 127.65it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1194.07it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 117.72it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1189.42it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:38<00:00, 129.48it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1148.32it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 127.34it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1145.11it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:38<00:00, 128.31it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1193.89it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:38<00:00, 128.43it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1151.28it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 125.67it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1194.58it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 127.71it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1148.46it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 127.17it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1194.91it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 126.27it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1191.91it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 124.26it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1139.08it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.95it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 959.43it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 123.46it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1043.37it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 121.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 8\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1141.63it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:38<00:00, 128.73it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1160.33it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 121.30it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1196.42it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:50<00:00, 99.06it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:07<00:00, 666.29it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 109.01it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 962.08it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 114.19it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1003.02it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:45<00:00, 110.94it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:06<00:00, 818.82it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [00:56<00:00, 88.56it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1014.91it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 115.59it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 988.90it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 116.55it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 943.93it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 114.78it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1004.50it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 113.86it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:05<00:00, 966.36it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [01:30<00:00, 55.08it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:07<00:00, 711.72it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 120.43it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1156.83it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 119.98it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1181.54it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 119.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 9\n",
      "Compensatory phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1149.77it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 119.81it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1134.02it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 119.00it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1107.67it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 119.00it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1184.53it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 118.19it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1092.53it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:42<00:00, 118.49it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1142.25it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:41<00:00, 121.48it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1179.82it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 122.27it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1042.42it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 122.82it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1194.56it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:43<00:00, 113.84it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1190.63it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 123.53it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1071.53it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 124.76it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1152.27it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 124.28it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1194.64it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:40<00:00, 124.72it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1134.33it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:39<00:00, 126.58it/s]\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:37: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  x_train = x.drop(task, axis=0)\n",
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1800/673721654.py:38: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  y_train = y.drop(task, axis=0)\n",
      "100%|█████████████████████████████████████| 5000/5000 [00:04<00:00, 1216.69it/s]\n",
      "100%|███████████████████████████████████████| 5000/5000 [01:21<00:00, 61.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg weight 10\n",
      "Compensatory phenotype\n"
     ]
    }
   ],
   "source": [
    "def task_maml(task,x,y):\n",
    "   # task='MXL' #the ethnic group we want to test\n",
    "#preparing training data by removing the task data from training data\n",
    "    x_train=x.drop(task,axis=0)\n",
    "    y_train=y.drop(task,axis=0)\n",
    "    eth_train=np.delete(eth,np.where(eth == task))\n",
    "    x_test=x.loc[task].to_numpy()\n",
    "    y_test=y.loc[task].to_numpy()\n",
    "    y_test=np.reshape(y_test,(-1,1))\n",
    "    eth_train=np.delete(eth, np.where(eth == task))\n",
    "\n",
    "    #train and test using different models\n",
    "    beta = base_linear_model(eth_train, x_train, y_train, x_test, y_test, epochs, batch_size)\n",
    "    lin_test_error = beta[1]\n",
    "    lin_r2=beta[2]\n",
    "\n",
    "    alpha=maml_model(eth_train,x_train,y_train,x_test,y_test,epochs,batch_size,num_task_sample)\n",
    "    maml_error=alpha[1]\n",
    "    maml_r2=alpha[2]\n",
    "\n",
    "\n",
    "#report correlation coefficeint or R^2\n",
    "    plt.plot(alpha[0])\n",
    "    plt.plot(beta[0])\n",
    "    plt.title('MSE ' + task)\n",
    "    plt.savefig('lin_maml_gen_results_'+task+'.png')\n",
    "\n",
    "\n",
    "    L = task, maml_error, lin_test_error,maml_r2, lin_r2\n",
    "    lin_error_vec.append(L)\n",
    "    #return error_vec\n",
    "\n",
    "\n",
    "def logistic_task_maml(task,x,y,reg_weight,model_type):\n",
    " # task='MXL' #the ethnic group we want to test\n",
    " # preparing training data by removing the task data from training data\n",
    " x_train = x.drop(task, axis=0)\n",
    " y_train = y.drop(task, axis=0)\n",
    " eth_train = np.delete(eth, np.where(eth == task))\n",
    " x_test = x.loc[task].to_numpy()\n",
    " y_test = y.loc[task].to_numpy()\n",
    " y_test = np.reshape(y_test, (-1, 1))\n",
    " eth_train = np.delete(eth, np.where(eth == task))\n",
    "\n",
    " beta = base_logistic_model(eth_train, x_train, y_train, x_test, y_test, epochs, batch_size,reg_weight)\n",
    " lin_test_error = beta[1]\n",
    "\n",
    " alpha = maml_logistic_model(eth_train, x_train, y_train, x_test, y_test, epochs, batch_size, num_task_sample,reg_weight)\n",
    " maml_error = alpha[1]\n",
    "\n",
    " L = task, maml_error, lin_test_error\n",
    " if(model_type=='hetero'):\n",
    "     hetero_acc_vec.append(L)\n",
    "     plt.plot(alpha[0])\n",
    "     plt.plot(beta[0])\n",
    "     plt.title('loss ' + task)\n",
    "     plt.savefig('hetero_maml_gen_results_' + task + '.png')\n",
    "\n",
    " if(model_type=='compensatory'):\n",
    "     compensatory_acc_vec.append(L)\n",
    "     #plt.plot(alpha[0])\n",
    "     #plt.plot(beta[0])\n",
    "     #plt.title('loss ' + task)\n",
    "     #plt.savefig('compensatory_maml_gen_results_' + task + '.png')\n",
    " #return logistic_vec\n",
    "#make changes so that all results are saved in a single file\n",
    "\n",
    "\n",
    "lin_error_vec=[]\n",
    "hetero_acc_vec=[]\n",
    "compensatory_acc_vec=[]\n",
    "weights_vec=np.arange(11)\n",
    "tasks= random.sample(list(eth),k=3)\n",
    "for reg in weights_vec:\n",
    "    for t in tasks:\n",
    "        for i in range(5):\n",
    "            x = data1\n",
    "            #y=linear_model(eth,data1)\n",
    "            #task_maml(t,x,y)\n",
    "\n",
    "            #y2= hetero_model(eth, data1)\n",
    "            #logistic_task_maml(t,x,y2,model_type='hetero')\n",
    "\n",
    "            y3=compensatory_model(eth,data1)\n",
    "            logistic_task_maml(t, x, y3,reg/10,model_type='compensatory')\n",
    "\n",
    "    L3 = pd.DataFrame(compensatory_acc_vec, columns=['task', 'maml_acc', 'lin_acc'])\n",
    "    # print('Linear phenotype')\n",
    "    # a=L1.groupby('task')\n",
    "    # print(a.mean())\n",
    "    # print('Heterogenous phenotype')\n",
    "    # b=L2.groupby('task')\n",
    "    # print(b.mean())\n",
    "    print('reg weight',reg)\n",
    "    print('Compensatory phenotype')\n",
    "    c = L3.groupby('task')\n",
    "    (c.mean()).to_csv('hyperparameter_optimization/reg'+str(reg)+'.csv')\n",
    "   # print(c.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4296b9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 206/206 [18:40<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "prop_var=[]\n",
    "for i in tqdm.tqdm(range(1,207)):\n",
    "    for j in range(1,50):\n",
    "        y,names=hetero_model(eth,data,max_threshold=j,num_heteromodel_causal_snps=i)\n",
    "        phenotype_subprop=0\n",
    "        subpop_phenotype_prop=[]\n",
    "        for subpop in eth:\n",
    "            subpop_phenotype_prop.append(sum(y.loc[subpop]==0)/y.loc[subpop].size)\n",
    "        phenotype_subprop= np.mean(subpop_phenotype_prop)\n",
    "        #print('num_causual_snps',i,'threshold',j,'average prop', phenotype_subprop,'variance',np.var(subpop_phenotype_prop))\n",
    "        prop_var.append([i,j,phenotype_subprop,np.var(subpop_phenotype_prop),names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fb4e9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var code_show_err = false; \n",
       "var code_toggle_err = function() {\n",
       " var stderrNodes = document.querySelectorAll('[data-mime-type=\"application/vnd.jupyter.stderr\"]')\n",
       " var stderr = Array.from(stderrNodes)\n",
       " if (code_show_err){\n",
       "     stderr.forEach(ele => ele.style.display = 'block');\n",
       " } else {\n",
       "     stderr.forEach(ele => ele.style.display = 'none');\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "document.addEventListener('DOMContentLoaded', code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a onclick=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "var code_show_err = false; \n",
    "var code_toggle_err = function() {\n",
    " var stderrNodes = document.querySelectorAll('[data-mime-type=\"application/vnd.jupyter.stderr\"]')\n",
    " var stderr = Array.from(stderrNodes)\n",
    " if (code_show_err){\n",
    "     stderr.forEach(ele => ele.style.display = 'block');\n",
    " } else {\n",
    "     stderr.forEach(ele => ele.style.display = 'none');\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "document.addEventListener('DOMContentLoaded', code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a onclick=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "caa55672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekshukla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    }
   ],
   "source": [
    "sweep_data=pd.DataFrame(np.vstack(prop_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "acf5d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=sweep_data[np.abs(sweep_data[2]-0.5)<0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e78d6e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578056</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>[250058, 337299]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.507147</td>\n",
       "      <td>0.036235</td>\n",
       "      <td>[332686, 374483]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.577633</td>\n",
       "      <td>0.051004</td>\n",
       "      <td>[186918, 18774665, 336350]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616316</td>\n",
       "      <td>0.083745</td>\n",
       "      <td>[90627, 305203, 118696]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>[16101460, 19860566, 307589, 231146, 451320, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1         2         3  \\\n",
       "49   2  1  0.578056  0.017251   \n",
       "50   2  2  0.507147  0.036235   \n",
       "99   3  2  0.577633  0.051004   \n",
       "100  3  3  0.616316  0.083745   \n",
       "400  9  9  0.350251  0.098266   \n",
       "\n",
       "                                                     4  \n",
       "49                                    [250058, 337299]  \n",
       "50                                    [332686, 374483]  \n",
       "99                          [186918, 18774665, 336350]  \n",
       "100                            [90627, 305203, 118696]  \n",
       "400  [16101460, 19860566, 307589, 231146, 451320, 4...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[alpha[3]<0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a061c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 1/4 [00:02<00:07,  2.63s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:05<00:05,  2.72s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:08<00:02,  2.84s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:11<00:00,  2.78s/it]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:11<00:44, 11.13s/it]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 1/4 [00:02<00:08,  2.78s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:05<00:05,  2.82s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:08<00:02,  2.73s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:11<00:00,  2.84s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:22<00:33, 11.28s/it]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 1/4 [00:03<00:09,  3.05s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:07<00:07,  3.58s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:10<00:03,  3.71s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  3.32s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:35<00:24, 12.21s/it]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 1/4 [00:02<00:07,  2.47s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.43s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.43s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:10<00:00,  2.54s/it]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [00:46<00:11, 11.41s/it]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████▎                                 | 1/4 [00:02<00:07,  2.65s/it]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:05<00:05,  2.56s/it]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:07<00:02,  2.54s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:10<00:00,  2.55s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:56<00:00, 11.25s/it]\n"
     ]
    }
   ],
   "source": [
    "compens_prop_var=[]\n",
    "for i in tqdm.tqdm(range(8,13)):\n",
    "    for j in tqdm.tqdm(range(18,22)):\n",
    "        for k in range(46,50):\n",
    "            for l in range(13,16):\n",
    "                y,snp1,snp2=compensatory_model(eth,data,max_threshold1=k, max_threshold2=l, num_heteromodel_causal_snps1=i,\n",
    "                               num_heteromodel_causal_snps2=j)\n",
    "                phenotype_subprop=0\n",
    "                subpop_phenotype_prop=[]\n",
    "                for subpop in eth:\n",
    "                    subpop_phenotype_prop.append(sum(y.loc[subpop]==0)/y.loc[subpop].size)\n",
    "                phenotype_subprop= np.mean(subpop_phenotype_prop)\n",
    "                #print('num_causual_snps',i,'threshold',j,'average prop', phenotype_subprop,'variance',np.var(subpop_phenotype_prop))\n",
    "                compens_prop_var.append([i,j,k,l,phenotype_subprop,np.var(subpop_phenotype_prop),snp1,snp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aeff810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8,\n",
       "  18,\n",
       "  46,\n",
       "  13,\n",
       "  0.3110262152431703,\n",
       "  0.1018468358415304,\n",
       "  array(['319932', '239649', '368580', '18629302', '18672785', '100189',\n",
       "         '363795', '18892411'], dtype=object),\n",
       "  array(['155716', '227956', '222652', '234557', '216512', '305203',\n",
       "         '384510', '18748059', '339622', '18459816', '337299', '240022',\n",
       "         '256591', '191770', '280230', '288689', '1076045'], dtype=object)],\n",
       " [8,\n",
       "  18,\n",
       "  46,\n",
       "  14,\n",
       "  0.10896106206373556,\n",
       "  0.0542561043128322,\n",
       "  array(['276250', '291784', '280464', '19785655', '175689', '87794',\n",
       "         '19792284', '19168107'], dtype=object),\n",
       "  array(['90627', '20936', '340890', '886568', '256424', '186961',\n",
       "         '18246623', '468152', '101217.1', '66541', '353221', '18672785',\n",
       "         '222652', '51479', '18185740', '157893', '257950'], dtype=object)],\n",
       " [8,\n",
       "  18,\n",
       "  47,\n",
       "  13,\n",
       "  0.19963289051723557,\n",
       "  0.0803098841251921,\n",
       "  array(['493007', '213063', '21833', '155716', '386839', '18629302',\n",
       "         '368845', '154290'], dtype=object),\n",
       "  array(['397177', '353221', '305308', '51150', '237093', '247693',\n",
       "         '117080', '19814493', '167376', '942451', '416880', '223694',\n",
       "         '18707056', '421413', '239636', '319932', '277015'], dtype=object)],\n",
       " [8,\n",
       "  18,\n",
       "  47,\n",
       "  14,\n",
       "  0.48725418986609254,\n",
       "  0.15862316910007715,\n",
       "  array(['288211', '387312', '18856677', '17011006', '18774665', '239649',\n",
       "         '212578', '283174'], dtype=object),\n",
       "  array(['285823', '124411', '18459816', '363795', '18246623', '18672785',\n",
       "         '205800', '821054', '102910', '155716', '50462', '17038385',\n",
       "         '456195', '415044', '18437217', '370975', '19904950'], dtype=object)],\n",
       " [8,\n",
       "  19,\n",
       "  46,\n",
       "  13,\n",
       "  0.3245573061538278,\n",
       "  0.12300821362316632,\n",
       "  array(['21833', '307589', '19785655', '212578', '101217', '1076045',\n",
       "         '204837', '942451'], dtype=object),\n",
       "  array(['973443', '101217.1', '355808', '314933', '19168107', '247693',\n",
       "         '155716', '144042', '239649', '19759145', '416226', '17011006',\n",
       "         '387312', '191314', '384510', '456195', '18856677', '17056070'],\n",
       "        dtype=object)],\n",
       " [8,\n",
       "  19,\n",
       "  46,\n",
       "  14,\n",
       "  0.3502271066283484,\n",
       "  0.12782607043934893,\n",
       "  array(['389017.1', '167376', '157893', '18774665', '918108', '332686',\n",
       "         '17038385', '256777'], dtype=object),\n",
       "  array(['434815', '155716', '285823', '364060', '399401', '277015',\n",
       "         '239636', '211156', '247693', '307140', '256978', '416226',\n",
       "         '18568062', '366216', '395797', '1076045', '148728', '387312'],\n",
       "        dtype=object)],\n",
       " [8,\n",
       "  19,\n",
       "  47,\n",
       "  13,\n",
       "  0.2898233453421826,\n",
       "  0.14585414447892567,\n",
       "  array(['105794', '139418', '223694', '212578', '397177', '117080',\n",
       "         '256591', '19881535'], dtype=object),\n",
       "  array(['213063', '336350', '18856677', '346484', '66541', '337299',\n",
       "         '18774665', '421413', '17011006', '19901633', '499561', '1039282',\n",
       "         '19759145', '234557', '77471', '170889', '384510', '353221'],\n",
       "        dtype=object)],\n",
       " [8,\n",
       "  19,\n",
       "  47,\n",
       "  14,\n",
       "  0.2937411329362536,\n",
       "  0.10549701842608891,\n",
       "  array(['307140', '387312', '105794', '19961472', '310558', '305308',\n",
       "         '19667261', '256978'], dtype=object),\n",
       "  array(['305203', '100189', '18748059', '77907', '242096', '309719',\n",
       "         '148728', '421413', '117080', '439152', '101217', '286089',\n",
       "         '179924', '369236', '329605', '19739107', '193882', '18668339'],\n",
       "        dtype=object)],\n",
       " [9,\n",
       "  18,\n",
       "  46,\n",
       "  13,\n",
       "  0.17113052065703596,\n",
       "  0.06957085486514653,\n",
       "  array(['247693', '105794', '278735', '19860566', '311447', '144042',\n",
       "         '20192154', '21833', '18246623'], dtype=object),\n",
       "  array(['18668339', '368845', '172167', '236224', '451320', '179924',\n",
       "         '256777', '284266', '389017', '80462', '277015', '231146',\n",
       "         '329605', '140806', '397177', '339622', '223694'], dtype=object)],\n",
       " [9,\n",
       "  18,\n",
       "  46,\n",
       "  14,\n",
       "  0.4089499487962335,\n",
       "  0.12383097658044136,\n",
       "  array(['139418', '309719', '415044', '239636', '277015', '416226',\n",
       "         '364060', '456195', '18286975'], dtype=object),\n",
       "  array(['20192154', '405457', '288211', '1039282', '314317', '18568062',\n",
       "         '19881535', '144042', '156656', '286089', '283174', '374483',\n",
       "         '310558', '193882', '342081', '256591', '50462'], dtype=object)],\n",
       " [9,\n",
       "  18,\n",
       "  47,\n",
       "  13,\n",
       "  0.2159595780118177,\n",
       "  0.10019428443203343,\n",
       "  array(['256591', '18286975', '221807', '119767', '157893', '291784',\n",
       "         '172167', '18824831', '19792284'], dtype=object),\n",
       "  array(['384510', '314933', '886568', '273402', '212578', '366216',\n",
       "         '258148', '117080', '17056070', '311447', '918108', '18488348',\n",
       "         '222652', '389017', '18228323', '156656', '19901633'], dtype=object)],\n",
       " [9,\n",
       "  18,\n",
       "  47,\n",
       "  14,\n",
       "  0.4858663147528234,\n",
       "  0.15543667866581665,\n",
       "  array(['421413.1', '179924', '342081', '184635', '314317', '417409',\n",
       "         '18856677', '100189', '387312'], dtype=object),\n",
       "  array(['374483', '242096', '20936', '484712', '499561', '18459816',\n",
       "         '19785655', '56198', '212578', '19837506', '240022', '336350',\n",
       "         '236224', '77471', '399401', '247693', '415044'], dtype=object)],\n",
       " [9,\n",
       "  19,\n",
       "  46,\n",
       "  13,\n",
       "  0.16596791861371574,\n",
       "  0.10766820063040207,\n",
       "  array(['365830', '186918', '191770', '87794', '421413', '306543',\n",
       "         '17038385', '20253163', '329605'], dtype=object),\n",
       "  array(['821054', '284266', '19961472', '18668339', '340890', '973443',\n",
       "         '183078', '80462', '283174', '389017', '223694', '493007',\n",
       "         '139418', '155716', '255573', '205800', '342081', '247693'],\n",
       "        dtype=object)],\n",
       " [9,\n",
       "  19,\n",
       "  46,\n",
       "  14,\n",
       "  0.3025323302925524,\n",
       "  0.09591311178849009,\n",
       "  array(['339622', '77471', '213063', '191770', '366216', '118696',\n",
       "         '451320', '456195', '101217'], dtype=object),\n",
       "  array(['18568062', '255573', '305624', '240022', '389017.1', '307589',\n",
       "         '16101460', '18748059', '17056070', '193882', '402953', '332686',\n",
       "         '319932', '87794', '337299', '234557', '90627', '362317'],\n",
       "        dtype=object)],\n",
       " [9,\n",
       "  19,\n",
       "  47,\n",
       "  13,\n",
       "  0.4309338532268326,\n",
       "  0.140082699303469,\n",
       "  array(['140806', '329605', '91530', '90627', '157893', '240022', '386839',\n",
       "         '186961', '306543'], dtype=object),\n",
       "  array(['468152', '353221', '421413', '19839130', '493007', '346394',\n",
       "         '179924', '126945', '193882', '18672785', '21833', '20936',\n",
       "         '283174', '18568062', '18228323', '258148', '307140', '439152'],\n",
       "        dtype=object)],\n",
       " [9,\n",
       "  19,\n",
       "  47,\n",
       "  14,\n",
       "  0.300059026892824,\n",
       "  0.11987089705352316,\n",
       "  array(['384510', '366216', '386839', '19904950', '342081', '19881535',\n",
       "         '451320', '213063', '51150'], dtype=object),\n",
       "  array(['172167', '305308', '119767', '66541', '306543', '370975',\n",
       "         '369236', '56198', '247693', '417409', '19901633', '389017',\n",
       "         '51479', '363795', '144042', '126945', '280230', '973443'],\n",
       "        dtype=object)]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compens_prop_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "640b4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekshukla/opt/anaconda3/lib/python3.8/site-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    }
   ],
   "source": [
    "csweep_data=pd.DataFrame(np.vstack(compens_prop_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0cebf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=csweep_data[np.abs(csweep_data[4]-0.5)<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "db70bf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   12\n",
       "1                                                   19\n",
       "2                                                   46\n",
       "3                                                   14\n",
       "4                                             0.490399\n",
       "5                                             0.108417\n",
       "6    [170889, 231146, 102910, 365830, 499561, 28821...\n",
       "7    [66541, 186918, 101217.1, 18707056, 119767, 19...\n",
       "Name: 205, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[beta[5]<0.15].loc[205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5d4f316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>0.311026</td>\n",
       "      <td>0.101847</td>\n",
       "      <td>[319932, 239649, 368580, 18629302, 18672785, 1...</td>\n",
       "      <td>[155716, 227956, 222652, 234557, 216512, 30520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>0.108961</td>\n",
       "      <td>0.054256</td>\n",
       "      <td>[276250, 291784, 280464, 19785655, 175689, 877...</td>\n",
       "      <td>[90627, 20936, 340890, 886568, 256424, 186961,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0.199633</td>\n",
       "      <td>0.08031</td>\n",
       "      <td>[493007, 213063, 21833, 155716, 386839, 186293...</td>\n",
       "      <td>[397177, 353221, 305308, 51150, 237093, 247693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0.487254</td>\n",
       "      <td>0.158623</td>\n",
       "      <td>[288211, 387312, 18856677, 17011006, 18774665,...</td>\n",
       "      <td>[285823, 124411, 18459816, 363795, 18246623, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>0.324557</td>\n",
       "      <td>0.123008</td>\n",
       "      <td>[21833, 307589, 19785655, 212578, 101217, 1076...</td>\n",
       "      <td>[973443, 101217.1, 355808, 314933, 19168107, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>0.350227</td>\n",
       "      <td>0.127826</td>\n",
       "      <td>[389017.1, 167376, 157893, 18774665, 918108, 3...</td>\n",
       "      <td>[434815, 155716, 285823, 364060, 399401, 27701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0.289823</td>\n",
       "      <td>0.145854</td>\n",
       "      <td>[105794, 139418, 223694, 212578, 397177, 11708...</td>\n",
       "      <td>[213063, 336350, 18856677, 346484, 66541, 3372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0.293741</td>\n",
       "      <td>0.105497</td>\n",
       "      <td>[307140, 387312, 105794, 19961472, 310558, 305...</td>\n",
       "      <td>[305203, 100189, 18748059, 77907, 242096, 3097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>0.171131</td>\n",
       "      <td>0.069571</td>\n",
       "      <td>[247693, 105794, 278735, 19860566, 311447, 144...</td>\n",
       "      <td>[18668339, 368845, 172167, 236224, 451320, 179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>0.40895</td>\n",
       "      <td>0.123831</td>\n",
       "      <td>[139418, 309719, 415044, 239636, 277015, 41622...</td>\n",
       "      <td>[20192154, 405457, 288211, 1039282, 314317, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0.21596</td>\n",
       "      <td>0.100194</td>\n",
       "      <td>[256591, 18286975, 221807, 119767, 157893, 291...</td>\n",
       "      <td>[384510, 314933, 886568, 273402, 212578, 36621...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0.485866</td>\n",
       "      <td>0.155437</td>\n",
       "      <td>[421413.1, 179924, 342081, 184635, 314317, 417...</td>\n",
       "      <td>[374483, 242096, 20936, 484712, 499561, 184598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>0.165968</td>\n",
       "      <td>0.107668</td>\n",
       "      <td>[365830, 186918, 191770, 87794, 421413, 306543...</td>\n",
       "      <td>[821054, 284266, 19961472, 18668339, 340890, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>0.302532</td>\n",
       "      <td>0.095913</td>\n",
       "      <td>[339622, 77471, 213063, 191770, 366216, 118696...</td>\n",
       "      <td>[18568062, 255573, 305624, 240022, 389017.1, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0.430934</td>\n",
       "      <td>0.140083</td>\n",
       "      <td>[140806, 329605, 91530, 90627, 157893, 240022,...</td>\n",
       "      <td>[468152, 353221, 421413, 19839130, 493007, 346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>0.300059</td>\n",
       "      <td>0.119871</td>\n",
       "      <td>[384510, 366216, 386839, 19904950, 342081, 198...</td>\n",
       "      <td>[172167, 305308, 119767, 66541, 306543, 370975...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3         4         5  \\\n",
       "0   8  18  46  13  0.311026  0.101847   \n",
       "1   8  18  46  14  0.108961  0.054256   \n",
       "2   8  18  47  13  0.199633   0.08031   \n",
       "3   8  18  47  14  0.487254  0.158623   \n",
       "4   8  19  46  13  0.324557  0.123008   \n",
       "5   8  19  46  14  0.350227  0.127826   \n",
       "6   8  19  47  13  0.289823  0.145854   \n",
       "7   8  19  47  14  0.293741  0.105497   \n",
       "8   9  18  46  13  0.171131  0.069571   \n",
       "9   9  18  46  14   0.40895  0.123831   \n",
       "10  9  18  47  13   0.21596  0.100194   \n",
       "11  9  18  47  14  0.485866  0.155437   \n",
       "12  9  19  46  13  0.165968  0.107668   \n",
       "13  9  19  46  14  0.302532  0.095913   \n",
       "14  9  19  47  13  0.430934  0.140083   \n",
       "15  9  19  47  14  0.300059  0.119871   \n",
       "\n",
       "                                                    6  \\\n",
       "0   [319932, 239649, 368580, 18629302, 18672785, 1...   \n",
       "1   [276250, 291784, 280464, 19785655, 175689, 877...   \n",
       "2   [493007, 213063, 21833, 155716, 386839, 186293...   \n",
       "3   [288211, 387312, 18856677, 17011006, 18774665,...   \n",
       "4   [21833, 307589, 19785655, 212578, 101217, 1076...   \n",
       "5   [389017.1, 167376, 157893, 18774665, 918108, 3...   \n",
       "6   [105794, 139418, 223694, 212578, 397177, 11708...   \n",
       "7   [307140, 387312, 105794, 19961472, 310558, 305...   \n",
       "8   [247693, 105794, 278735, 19860566, 311447, 144...   \n",
       "9   [139418, 309719, 415044, 239636, 277015, 41622...   \n",
       "10  [256591, 18286975, 221807, 119767, 157893, 291...   \n",
       "11  [421413.1, 179924, 342081, 184635, 314317, 417...   \n",
       "12  [365830, 186918, 191770, 87794, 421413, 306543...   \n",
       "13  [339622, 77471, 213063, 191770, 366216, 118696...   \n",
       "14  [140806, 329605, 91530, 90627, 157893, 240022,...   \n",
       "15  [384510, 366216, 386839, 19904950, 342081, 198...   \n",
       "\n",
       "                                                    7  \n",
       "0   [155716, 227956, 222652, 234557, 216512, 30520...  \n",
       "1   [90627, 20936, 340890, 886568, 256424, 186961,...  \n",
       "2   [397177, 353221, 305308, 51150, 237093, 247693...  \n",
       "3   [285823, 124411, 18459816, 363795, 18246623, 1...  \n",
       "4   [973443, 101217.1, 355808, 314933, 19168107, 2...  \n",
       "5   [434815, 155716, 285823, 364060, 399401, 27701...  \n",
       "6   [213063, 336350, 18856677, 346484, 66541, 3372...  \n",
       "7   [305203, 100189, 18748059, 77907, 242096, 3097...  \n",
       "8   [18668339, 368845, 172167, 236224, 451320, 179...  \n",
       "9   [20192154, 405457, 288211, 1039282, 314317, 18...  \n",
       "10  [384510, 314933, 886568, 273402, 212578, 36621...  \n",
       "11  [374483, 242096, 20936, 484712, 499561, 184598...  \n",
       "12  [821054, 284266, 19961472, 18668339, 340890, 9...  \n",
       "13  [18568062, 255573, 305624, 240022, 389017.1, 3...  \n",
       "14  [468152, 353221, 421413, 19839130, 493007, 346...  \n",
       "15  [172167, 305308, 119767, 66541, 306543, 370975...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csweep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2aae18fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "maml_acc    0.982428\n",
      "lin_acc     0.986871\n",
      "dtype: float64\n",
      "-0.004442818959554007\n",
      "1\n",
      "maml_acc    0.980151\n",
      "lin_acc     0.980603\n",
      "dtype: float64\n",
      "-0.00045185089111332566\n",
      "2\n",
      "maml_acc    0.986250\n",
      "lin_acc     0.983712\n",
      "dtype: float64\n",
      "0.0025384691026475448\n",
      "3\n",
      "maml_acc    0.968377\n",
      "lin_acc     0.967478\n",
      "dtype: float64\n",
      "0.0008994738260906798\n",
      "4\n",
      "maml_acc    0.971514\n",
      "lin_acc     0.970693\n",
      "dtype: float64\n",
      "0.0008215586344402226\n",
      "5\n",
      "maml_acc    0.967963\n",
      "lin_acc     0.966407\n",
      "dtype: float64\n",
      "0.0015558454725477233\n",
      "6\n",
      "maml_acc    0.966335\n",
      "lin_acc     0.965959\n",
      "dtype: float64\n",
      "0.00037598382858994306\n",
      "7\n",
      "maml_acc    0.960883\n",
      "lin_acc     0.963364\n",
      "dtype: float64\n",
      "-0.002481365203857333\n",
      "8\n",
      "maml_acc    0.961727\n",
      "lin_acc     0.964110\n",
      "dtype: float64\n",
      "-0.0023826316550925597\n",
      "9\n",
      "maml_acc    0.958852\n",
      "lin_acc     0.963063\n",
      "dtype: float64\n",
      "-0.0042105102539062855\n",
      "10\n",
      "maml_acc    0.957979\n",
      "lin_acc     0.962614\n",
      "dtype: float64\n",
      "-0.0046350652521307545\n"
     ]
    }
   ],
   "source": [
    "#find average accuracy\n",
    "for i in range(11):\n",
    "    a=pd.read_csv('hyperparameter_optimization/reg'+str(i)+'.csv',index_col=[0])\n",
    "    print(i)\n",
    "    print(a.mean())\n",
    "    print(a.mean()[0]-a.mean()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c15875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(eth, x, hsq=0.1):\n",
    "    # dictionary which contains randomly generated coefficnets for the linear model\n",
    "    eth_coef = {}\n",
    "    eth_errors = {}\n",
    "    #eth_errors_sigma2 = np.ndarray()\n",
    "    #eth_errors.update([(ethnicity, errors / 100) for ethnicity, errors in zip(eth, eth_errors_sigma2)])\n",
    "    #varx=np.sum(np.multiply(np.cov(x,rowvar=False),np.identity(x.shape[1])))\n",
    "    #eth_errors_sigma2=-varx+ (varx/hsq)\n",
    "    for i in eth:\n",
    "        varx = np.sum(np.multiply(np.cov(x.loc[i], rowvar=False), np.identity(x.shape[1])))\n",
    "        eth_errors[i]=-varx+ (varx/hsq)\n",
    "        print(i,eth_errors[i])\n",
    "    #eth_errors.update(eth,eth_errors.values()/np.max(eth_errors.values()))\n",
    "    total = sum(eth_errors.values(), 0.0)\n",
    "    eth_errors = {k: v / total for k, v in eth_errors.items()}\n",
    "    print(eth_errors)\n",
    "    for i in eth:\n",
    "        eth_coef[i] = np.random.uniform(-1, 1, (x.shape[1]))\n",
    "\n",
    "    y = x.apply(lambda a: a @ eth_coef[a.name[0]] + np.random.normal(scale=eth_errors[a.name[0]]), axis=1)\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "111b5fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR 442.87252747252745\n",
      "FIN 444.2486085343228\n",
      "EAS 425.20524916943526\n",
      "PUR 523.266990291262\n",
      "CLM 495.2244337680163\n",
      "IBS 445.83406806559685\n",
      "PEL 450.52184873949574\n",
      "SAS 480.387396071816\n",
      "KHV 422.482374768089\n",
      "ACB 548.010197368421\n",
      "GWD 523.7977243994942\n",
      "ESN 529.7588126159553\n",
      "MSL 518.8840336134454\n",
      "STU 474.36080372743146\n",
      "EUR 450.0055658627086\n",
      "YRI 529.147945688591\n",
      "JPT 428.21079163554884\n",
      "LWK 537.6567717996289\n",
      "ASW 539.0360655737704\n",
      "MXL 480.98660714285717\n",
      "TSI 457.93193440310347\n",
      "{'GBR': 0.043642088477034886, 'FIN': 0.04377769194693892, 'EAS': 0.04190109784198183, 'PUR': 0.05156441836148804, 'CLM': 0.04880101431858168, 'IBS': 0.04393392824711203, 'PEL': 0.044395877287163786, 'SAS': 0.04733892472912336, 'KHV': 0.041632777008866306, 'ACB': 0.05400269385947308, 'GWD': 0.05161671861375575, 'ESN': 0.052204143489367034, 'MSL': 0.05113250766200093, 'STU': 0.04674504486529513, 'EUR': 0.044345001105892144, 'YRI': 0.05214394669042836, 'JPT': 0.04219727369866951, 'LWK': 0.05298243388242664, 'ASW': 0.0531183539433761, 'MXL': 0.047397972922354134, 'TSI': 0.04512609104867022}\n"
     ]
    }
   ],
   "source": [
    "y=linear_model(eth,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0f409d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eth  ID     \n",
       "GBR  HG00096    -306.301587\n",
       "     HG00097     863.037892\n",
       "     HG00099    -394.822695\n",
       "     HG00100    -461.646395\n",
       "     HG00101     335.934810\n",
       "                   ...     \n",
       "SAS  NA21137     826.755650\n",
       "     NA21141    -373.720839\n",
       "     NA21142     367.485953\n",
       "     NA21143   -1241.330977\n",
       "     NA21144    -831.597308\n",
       "Length: 2503, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4379250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethID=pd.read_csv('ethID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d1357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       FIN\n",
       "1       FIN\n",
       "2       FIN\n",
       "3       FIN\n",
       "4       FIN\n",
       "       ... \n",
       "2704    GIH\n",
       "2705    GIH\n",
       "2706    GIH\n",
       "2707    GIH\n",
       "2708    GIH\n",
       "Name: eth, Length: 2709, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethID['eth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06abaa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>51479</th>\n",
       "      <th>821054</th>\n",
       "      <th>886568</th>\n",
       "      <th>918108</th>\n",
       "      <th>942451</th>\n",
       "      <th>973443</th>\n",
       "      <th>998741</th>\n",
       "      <th>1039282</th>\n",
       "      <th>1076045</th>\n",
       "      <th>21833</th>\n",
       "      <th>...</th>\n",
       "      <th>154290</th>\n",
       "      <th>175689</th>\n",
       "      <th>211156</th>\n",
       "      <th>239649</th>\n",
       "      <th>256777</th>\n",
       "      <th>280230</th>\n",
       "      <th>307589</th>\n",
       "      <th>339622</th>\n",
       "      <th>368580</th>\n",
       "      <th>384510</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth</th>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">GBR</th>\n",
       "      <th>HG00096</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">SAS</th>\n",
       "      <th>NA21137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21141</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21142</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21144</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             51479  821054  886568  918108  942451  973443  998741  1039282  \\\n",
       "eth ID                                                                        \n",
       "GBR HG00096      1       1       2       0       2       0       1        2   \n",
       "    HG00097      0       0       2       0       2       1       0        2   \n",
       "    HG00099      0       1       2       0       2       0       0        2   \n",
       "    HG00100      0       0       2       0       2       1       0        2   \n",
       "    HG00101      0       0       2       0       2       0       1        1   \n",
       "...            ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "SAS NA21137      0       0       2       0       2       1       0        1   \n",
       "    NA21141      1       0       2       0       2       1       0        2   \n",
       "    NA21142      0       1       2       0       2       1       1        2   \n",
       "    NA21143      0       0       2       0       2       0       1        2   \n",
       "    NA21144      0       1       2       0       2       1       1        2   \n",
       "\n",
       "             1076045  21833  ...  154290  175689  211156  239649  256777  \\\n",
       "eth ID                       ...                                           \n",
       "GBR HG00096        0      0  ...       2       1       1       0       2   \n",
       "    HG00097        0      0  ...       2       1       1       0       1   \n",
       "    HG00099        0      0  ...       2       1       2       0       0   \n",
       "    HG00100        0      0  ...       2       2       0       0       2   \n",
       "    HG00101        0      0  ...       2       1       1       0       2   \n",
       "...              ...    ...  ...     ...     ...     ...     ...     ...   \n",
       "SAS NA21137        0      0  ...       2       2       1       0       2   \n",
       "    NA21141        0      0  ...       2       2       0       0       2   \n",
       "    NA21142        0      0  ...       2       1       1       0       1   \n",
       "    NA21143        0      0  ...       2       1       2       1       2   \n",
       "    NA21144        0      0  ...       2       2       0       0       0   \n",
       "\n",
       "             280230  307589  339622  368580  384510  \n",
       "eth ID                                               \n",
       "GBR HG00096       2       1       0       2       1  \n",
       "    HG00097       1       2       0       1       1  \n",
       "    HG00099       1       2       0       0       0  \n",
       "    HG00100       0       1       0       1       0  \n",
       "    HG00101       2       1       0       2       1  \n",
       "...             ...     ...     ...     ...     ...  \n",
       "SAS NA21137       1       1       0       0       0  \n",
       "    NA21141       2       0       1       2       2  \n",
       "    NA21142       2       1       0       1       2  \n",
       "    NA21143       1       2       0       0       0  \n",
       "    NA21144       0       1       0       2       1  \n",
       "\n",
       "[2503 rows x 206 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d76d5ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/long_lab/1000_Genome_Data/20181203_biallelic_SNV/ftp.1000genomes.ebi.ac.uk/ALL.chr1.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_33363/2769754560.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mheader_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m data1=pd.read_csv('/work/long_lab/1000_Genome_Data/20181203_biallelic_SNV/ftp.1000genomes.ebi.ac.uk/ALL.chr'+ str(i) +'.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz',sep='\\t',\n\u001b[0m\u001b[1;32m     12\u001b[0m                 header=header_line,nrows=2000)\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0;31m# error: Incompatible types in assignment (expression has type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;31m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                 handle = gzip.GzipFile(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    715\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/long_lab/1000_Genome_Data/20181203_biallelic_SNV/ftp.1000genomes.ebi.ac.uk/ALL.chr1.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#read data\n",
    "ethnic_dic=pd.read_csv('sampleID.csv',usecols=['Sample (Male/Female/Unknown)','Population(s)'])\n",
    "#num_rows=20000\n",
    "header_line=19\n",
    "i=1\n",
    "data1=pd.read_csv('/work/long_lab/1000_Genome_Data/20181203_biallelic_SNV/ftp.1000genomes.ebi.ac.uk/ALL.chr'+ str(i) +'.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz',sep='\\t',\n",
    "                header=header_line,nrows=2000)\n",
    "for i in range(2,21):\n",
    "    data=pd.read_csv('/work/long_lab/1000_Genome_Data/20181203_biallelic_SNV/ftp.1000genomes.ebi.ac.uk/ALL.chr'+ str(i) +'.shapeit2_integrated_v1a.GRCh38.20181129.phased.vcf.gz',sep='\\t',\n",
    "                header=header_line,nrows=2000)\n",
    "    data1=pd.concat([data1,data])\n",
    "\n",
    "#print(data1.head)\n",
    "#task='MXL' #the ethnic group we want to test\n",
    "removal_list=['HG00104',\n",
    " 'HG00134',\n",
    " 'HG00135',\n",
    " 'HG00152',\n",
    " 'HG00156',\n",
    " 'HG00249',\n",
    " 'HG00270',\n",
    " 'HG00302',\n",
    " 'HG00303',\n",
    " 'HG00312',\n",
    " 'HG00359',\n",
    " 'HG00377',\n",
    " 'HG01471',\n",
    " 'HG02168',\n",
    " 'HG02169',\n",
    " 'HG02170',\n",
    " 'HG02173',\n",
    " 'HG02176',\n",
    " 'HG02358',\n",
    " 'HG02405',\n",
    " 'HG02436',\n",
    " 'HG03171',\n",
    " 'HG03393',\n",
    " 'HG03398',\n",
    " 'HG03431',\n",
    " 'HG03462',\n",
    " 'HG03549',\n",
    " 'HG04301',\n",
    " 'HG04302',\n",
    " 'HG04303',\n",
    " 'NA18527',\n",
    " 'NA18576',\n",
    " 'NA18791',\n",
    " 'NA18955',\n",
    " 'NA19044',\n",
    " 'NA19359',\n",
    " 'NA19371',\n",
    " 'NA19398',\n",
    " 'NA20537',\n",
    " 'NA20816',\n",
    " 'NA20829',\n",
    " 'NA20831',\n",
    " 'NA20873',\n",
    " 'NA20883',\n",
    " 'NA21121']\n",
    "\n",
    "\n",
    "#processing data\n",
    "def process_dict(data):\n",
    "    data=data.rename(columns={'Sample (Male/Female/Unknown)':'ID','Population(s)':'eth'})\n",
    "    data['eth']=data['eth'].apply(lambda x: x.split(',')[-1][1:])\n",
    "    data['ID']=data['ID'].apply(lambda x: x.split(' ')[0])\n",
    "    data.index=data['ID']\n",
    "    data=data.drop('ID',axis=1)\n",
    "    data=data.drop('NA18498')\n",
    "    return data\n",
    "\n",
    "def process_data(data,num_causal_snps=20):\n",
    "    data=data[data['ALT'].isin(['A','C','G','T'])] #select SNPs with single ALT allele\n",
    "    data['INFO']=data['INFO'].apply(lambda x: float(x.split(';')[3].split('=')[-1])) #extract allele freq information\n",
    "    data=data[data['INFO']>0.05] #choose SNPs with allele freq more than 0.05\n",
    "    data.index=data['POS'] #set ID col as index\n",
    "    data=data.drop(['ID','#CHROM','POS','REF','ALT','QUAL','FILTER','INFO','FORMAT'],axis=1) #drop columns other than individual data\n",
    "    data=data.applymap(lambda x: 2 if x=='1|1' else(0 if x=='0|0' else 1)) #sets 0|0 to 0 ...\n",
    "    #data=data.drop(removal_list,axis=1)\n",
    "    data=data.T\n",
    "    causal_snps=np.arange(0,len(data.columns),len(data.columns)//num_causal_snps)\n",
    "    data=data[data.columns[causal_snps]]\n",
    "    data['eth']=ethID['eth']\n",
    "    data['ID']=data.index\n",
    "    data=data.set_index(['eth','ID'])\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#eth_ID=process_dict(ethnic_dic)\n",
    "#eth=eth_ID['eth'].unique()\n",
    "ethID=pd.read_csv('ethID.csv')\n",
    "eth=ethID['eth'].unique()\n",
    "\n",
    "\n",
    "data1=process_data(data)\n",
    "#data1.to_csv('processed_data_mar21.csv')\n",
    "#eth_ID.to_csv('eth_ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e98d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('processed_data_mar21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dabff065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth</th>\n",
       "      <th>ID</th>\n",
       "      <th>61849</th>\n",
       "      <th>72982</th>\n",
       "      <th>82590</th>\n",
       "      <th>88108</th>\n",
       "      <th>98593</th>\n",
       "      <th>101438</th>\n",
       "      <th>102611</th>\n",
       "      <th>106775</th>\n",
       "      <th>...</th>\n",
       "      <th>119864</th>\n",
       "      <th>123001</th>\n",
       "      <th>126972</th>\n",
       "      <th>128317</th>\n",
       "      <th>132236</th>\n",
       "      <th>137509</th>\n",
       "      <th>140837</th>\n",
       "      <th>144480</th>\n",
       "      <th>146119</th>\n",
       "      <th>148072</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HG00096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HG00097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HG00099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HG00100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HG00101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NA21137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NA21141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NA21142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NA21143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NA21144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      eth       ID  61849  72982  82590  88108  98593  101438  102611  106775  \\\n",
       "0     NaN  HG00096      0      0      0      2      2       1       2       1   \n",
       "1     NaN  HG00097      0      0      0      0      0       0       1       1   \n",
       "2     NaN  HG00099      0      0      0      0      0       0       2       2   \n",
       "3     NaN  HG00100      0      0      0      1      1       1       1       1   \n",
       "4     NaN  HG00101      1      1      0      2      0       2       1       1   \n",
       "...   ...      ...    ...    ...    ...    ...    ...     ...     ...     ...   \n",
       "2498  NaN  NA21137      0      0      1      2      0       1       2       1   \n",
       "2499  NaN  NA21141      1      1      0      2      1       0       1       1   \n",
       "2500  NaN  NA21142      1      1      0      2      2       0       0       2   \n",
       "2501  NaN  NA21143      0      0      1      2      0       0       1       1   \n",
       "2502  NaN  NA21144      0      0      0      2      2       0       1       2   \n",
       "\n",
       "      ...  119864  123001  126972  128317  132236  137509  140837  144480  \\\n",
       "0     ...       0       0       0       1       1       0       0       1   \n",
       "1     ...       0       0       0       1       1       0       0       1   \n",
       "2     ...       0       0       0       2       0       0       0       2   \n",
       "3     ...       0       0       0       0       1       0       1       0   \n",
       "4     ...       0       0       0       1       1       0       0       1   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2498  ...       1       1       1       0       1       1       1       0   \n",
       "2499  ...       0       0       0       0       0       0       1       0   \n",
       "2500  ...       1       1       1       1       0       1       1       1   \n",
       "2501  ...       1       1       1       0       0       1       1       0   \n",
       "2502  ...       1       1       1       1       0       1       1       1   \n",
       "\n",
       "      146119  148072  \n",
       "0          1       1  \n",
       "1          1       1  \n",
       "2          1       1  \n",
       "3          2       2  \n",
       "4          1       1  \n",
       "...      ...     ...  \n",
       "2498       2       2  \n",
       "2499       2       2  \n",
       "2500       0       0  \n",
       "2501       1       1  \n",
       "2502       0       0  \n",
       "\n",
       "[2503 rows x 24 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f6f9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ethID['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46b87993",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=data1['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fbb6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "bthings=[]\n",
    "notbthings=[]\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(b)):\n",
    "        if a[i]==b[j]:\n",
    "            bthings.append(i)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53a6f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=pd.read_csv('processed_data_mar21_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c88fea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=data4.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d96f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['eth']='ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "100389ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs=data4['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "668b829d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4['ID'][1]==ethID['ID'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ae55d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_33363/2534360933.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data4['eth'][i]=ethID['eth'][j]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2548):\n",
    "    for j in range(2709):\n",
    "        if data4['ID'][i]==ethID['ID'][j]:\n",
    "            data4['eth'][i]=ethID['eth'][j]\n",
    "            continue\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f65df33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4=data4.set_index(['eth','ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f564cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.to_csv('processed_data_mar21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fba559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.set_index(['eth','ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5a1afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_7209/2898487317.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['eth'][i]=eth_ID['eth'].iloc[j]\n"
     ]
    }
   ],
   "source": [
    "rows_remove_list=[]\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(eth_ID.shape[0]):\n",
    "        flag=0\n",
    "        #print(i,j,data.iloc[i].name,eth_ID['ID'].iloc[j])\n",
    "        if(data.iloc[i].name==eth_ID['ID'].iloc[j]):\n",
    "            #print('si')\n",
    "            data['eth'][i]=eth_ID['eth'].iloc[j]\n",
    "            continue\n",
    "    if flag==0:\n",
    "            rows_remove_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f2d1361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " 2547,\n",
       " ...]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83cebd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('processed_data_apr05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a434146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>POS</th>\n",
       "      <th>61849</th>\n",
       "      <th>65955</th>\n",
       "      <th>66369</th>\n",
       "      <th>67744</th>\n",
       "      <th>68303</th>\n",
       "      <th>72450</th>\n",
       "      <th>72982</th>\n",
       "      <th>73765</th>\n",
       "      <th>77005</th>\n",
       "      <th>78705</th>\n",
       "      <th>...</th>\n",
       "      <th>2000377</th>\n",
       "      <th>2000733</th>\n",
       "      <th>2001588</th>\n",
       "      <th>2001665</th>\n",
       "      <th>2002396</th>\n",
       "      <th>2002459</th>\n",
       "      <th>2003829</th>\n",
       "      <th>2004055</th>\n",
       "      <th>2004404</th>\n",
       "      <th>2004447</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACB</th>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASW</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEB</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDX</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEU</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHB</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHS</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLM</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESN</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIN</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GIH</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GWD</th>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBS</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITU</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPT</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KHV</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LWK</th>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSL</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MXL</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEL</th>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PJL</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUR</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STU</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSI</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YRI</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 5917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "POS  61849    65955    66369    67744    68303    72450    72982    73765    \\\n",
       "eth                                                                           \n",
       "ACB       97       97       97       97       97       97       97       97   \n",
       "ASW       61       61       61       61       61       61       61       61   \n",
       "BEB       86       86       86       86       86       86       86       86   \n",
       "CDX      100      100      100      100      100      100      100      100   \n",
       "CEU       99       99       99       99       99       99       99       99   \n",
       "CHB      106      106      106      106      106      106      106      106   \n",
       "CHS      105      105      105      105      105      105      105      105   \n",
       "CLM       95       95       95       95       95       95       95       95   \n",
       "ESN      100      100      100      100      100      100      100      100   \n",
       "FIN      105      105      105      105      105      105      105      105   \n",
       "GBR      100      100      100      100      100      100      100      100   \n",
       "GIH      106      106      106      106      106      106      106      106   \n",
       "GWD      113      113      113      113      113      113      113      113   \n",
       "IBS      107      107      107      107      107      107      107      107   \n",
       "ITU      102      102      102      102      102      102      102      102   \n",
       "JPT      105      105      105      105      105      105      105      105   \n",
       "KHV       99       99       99       99       99       99       99       99   \n",
       "LWK      103      103      103      103      103      103      103      103   \n",
       "MSL       90       90       90       90       90       90       90       90   \n",
       "MXL       64       64       64       64       64       64       64       64   \n",
       "PEL       85       85       85       85       85       85       85       85   \n",
       "PJL       96       96       96       96       96       96       96       96   \n",
       "PUR      104      104      104      104      104      104      104      104   \n",
       "STU      102      102      102      102      102      102      102      102   \n",
       "TSI      111      111      111      111      111      111      111      111   \n",
       "YRI      107      107      107      107      107      107      107      107   \n",
       "\n",
       "POS  77005    78705    ...  2000377  2000733  2001588  2001665  2002396  \\\n",
       "eth                    ...                                                \n",
       "ACB       97       97  ...       97       97       97       97       97   \n",
       "ASW       61       61  ...       61       61       61       61       61   \n",
       "BEB       86       86  ...       86       86       86       86       86   \n",
       "CDX      100      100  ...      100      100      100      100      100   \n",
       "CEU       99       99  ...       99       99       99       99       99   \n",
       "CHB      106      106  ...      106      106      106      106      106   \n",
       "CHS      105      105  ...      105      105      105      105      105   \n",
       "CLM       95       95  ...       95       95       95       95       95   \n",
       "ESN      100      100  ...      100      100      100      100      100   \n",
       "FIN      105      105  ...      105      105      105      105      105   \n",
       "GBR      100      100  ...      100      100      100      100      100   \n",
       "GIH      106      106  ...      106      106      106      106      106   \n",
       "GWD      113      113  ...      113      113      113      113      113   \n",
       "IBS      107      107  ...      107      107      107      107      107   \n",
       "ITU      102      102  ...      102      102      102      102      102   \n",
       "JPT      105      105  ...      105      105      105      105      105   \n",
       "KHV       99       99  ...       99       99       99       99       99   \n",
       "LWK      103      103  ...      103      103      103      103      103   \n",
       "MSL       90       90  ...       90       90       90       90       90   \n",
       "MXL       64       64  ...       64       64       64       64       64   \n",
       "PEL       85       85  ...       85       85       85       85       85   \n",
       "PJL       96       96  ...       96       96       96       96       96   \n",
       "PUR      104      104  ...      104      104      104      104      104   \n",
       "STU      102      102  ...      102      102      102      102      102   \n",
       "TSI      111      111  ...      111      111      111      111      111   \n",
       "YRI      107      107  ...      107      107      107      107      107   \n",
       "\n",
       "POS  2002459  2003829  2004055  2004404  2004447  \n",
       "eth                                               \n",
       "ACB       97       97       97       97       97  \n",
       "ASW       61       61       61       61       61  \n",
       "BEB       86       86       86       86       86  \n",
       "CDX      100      100      100      100      100  \n",
       "CEU       99       99       99       99       99  \n",
       "CHB      106      106      106      106      106  \n",
       "CHS      105      105      105      105      105  \n",
       "CLM       95       95       95       95       95  \n",
       "ESN      100      100      100      100      100  \n",
       "FIN      105      105      105      105      105  \n",
       "GBR      100      100      100      100      100  \n",
       "GIH      106      106      106      106      106  \n",
       "GWD      113      113      113      113      113  \n",
       "IBS      107      107      107      107      107  \n",
       "ITU      102      102      102      102      102  \n",
       "JPT      105      105      105      105      105  \n",
       "KHV       99       99       99       99       99  \n",
       "LWK      103      103      103      103      103  \n",
       "MSL       90       90       90       90       90  \n",
       "MXL       64       64       64       64       64  \n",
       "PEL       85       85       85       85       85  \n",
       "PJL       96       96       96       96       96  \n",
       "PUR      104      104      104      104      104  \n",
       "STU      102      102      102      102      102  \n",
       "TSI      111      111      111      111      111  \n",
       "YRI      107      107      107      107      107  \n",
       "\n",
       "[26 rows x 5917 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('eth').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa0573e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>eth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00315</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00327</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00334</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00339</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00341</td>\n",
       "      <td>FIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>NA20905</td>\n",
       "      <td>GIH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>NA21092</td>\n",
       "      <td>GIH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>NA21117</td>\n",
       "      <td>GIH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>NA21124</td>\n",
       "      <td>GIH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>NA21129</td>\n",
       "      <td>GIH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  eth\n",
       "0     HG00315  FIN\n",
       "1     HG00327  FIN\n",
       "2     HG00334  FIN\n",
       "3     HG00339  FIN\n",
       "4     HG00341  FIN\n",
       "...       ...  ...\n",
       "2704  NA20905  GIH\n",
       "2705  NA21092  GIH\n",
       "2706  NA21117  GIH\n",
       "2707  NA21124  GIH\n",
       "2708  NA21129  GIH\n",
       "\n",
       "[2548 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b5ff79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_ID=ethID.drop(rows_remove_list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d8a2c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_ID.to_csv('eth_ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb461737",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_ID=pd.read_csv('eth_ID.csv',index_col=[0])\n",
    "eth=eth_ID['eth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7685b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('processed_data_mar29_raw_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385fdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['eth']=eth_ID['eth']\n",
    "data['ID']=data.index\n",
    "data=data.set_index(['eth','ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8227a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c61b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['eth'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcab5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index=data['POS'] #set ID col as index\n",
    "data=data.drop(['ID','#CHROM','POS','POS.1','REF','ALT','QUAL','FILTER','INFO','FORMAT'],axis=1) #drop columns other than individual data\n",
    "data=data.applymap(lambda x: 2 if x=='1|1' else(0 if x=='0|0' else 1)) #sets 0|0 to 0 ...\n",
    "#data=data.drop(removal_list,axis=1)\n",
    "data=data.T\n",
    "#data=data[data.columns[causal_snps]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4877c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['eth']=eth_ID['eth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf65872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ID']=data.index\n",
    "data=data.set_index(['eth','ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c163487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       FIN\n",
       "1       FIN\n",
       "2       FIN\n",
       "3       FIN\n",
       "4       FIN\n",
       "       ... \n",
       "2704    GIH\n",
       "2705    GIH\n",
       "2706    GIH\n",
       "2707    GIH\n",
       "2708    GIH\n",
       "Name: eth, Length: 2548, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth_ID['eth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fee919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
