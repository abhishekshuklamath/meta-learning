{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "8f95a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import vmap,grad\n",
    "from functools import partial\n",
    "from jax.example_libraries import stax\n",
    "from jax.example_libraries.stax import Dense,Relu,Flatten\n",
    "#from jax import random\n",
    "import random\n",
    "from jax import jit\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "import numpy as onp\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.tree_util import tree_multimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "04be0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data1.shape[1] #number of causal snps\n",
    "reg_weight=1\n",
    "in_shape=(-1,features)\n",
    "ethnic_grp_min_pop=66 #min population among all subpopulatiosn\n",
    "batch_size=50 #inner batch size for inner loop\n",
    "K=20 #K-shot learning\n",
    "num_task_sample= 4 #number of tasks to sample to meta train\n",
    "lr=0.1\n",
    "rng=jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9abae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_init,net_apply=stax.serial(\n",
    "#    Flatten,Dense(2),Relu,Dense(num_classes),stax.elementwise(jax.nn.log_softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "a73e01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_init,net_apply=stax.serial(\n",
    "  Dense(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "28254c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_shape, net_params=net_init(rng,input_shape=in_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90423e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for non-linear model \n",
    "#def cross_entropy(logprobs, targets):\n",
    "#  nll = np.take_along_axis(logprobs, np.expand_dims(targets, axis=1), axis=1)\n",
    "#  ce = -np.mean(nll)\n",
    "#  return ce\n",
    "\n",
    "#def loss(params,batch):\n",
    " #   inputs, targets = batch\n",
    "  #  predictions=net_apply(params,inputs)\n",
    "   # return cross_entropy(predictions,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data,test_data=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "238b4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params,data,targets):\n",
    "    predictions=net_apply(params,inputs)\n",
    "    for i in range(len(net_params)):\n",
    "        l1_params=np.linalg.norm(net_params[i],1)\n",
    "    return np.mean((targets-predictions)**2) + reg_weight*np.linalg.norm(net_params[0][0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "964a9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_update(p,x1,y1):\n",
    "    grads= grad(loss)(p,x1,y1)\n",
    "    inner_sgd_fn= lambda g, state: (state-lr*g)\n",
    "    return tree_multimap(inner_sgd_fn,grads,p)\n",
    "\n",
    "def maml_loss(p,x1,y1,x2,y2):\n",
    "    p2= inner_update(p,x1,y1)\n",
    "    return loss(p2,x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0872c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = optimizers.adam(step_size=1e-3)\n",
    "out_shape, net_params= net_init(rng,in_shape)\n",
    "opt_state = opt_init(net_params)\n",
    "\n",
    "@jit\n",
    "def step(i,opt_state,x1,y1,x2,y2):\n",
    "    p=get_params(opt_state)\n",
    "    g= grad(maml_loss)(p,x1,y1,x2,y2)\n",
    "    l=maml_loss(p,x1,y1,x2,y2)\n",
    "    return opt_update(i,g,opt_state),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "2366bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_maml_loss(p, x1_b, y1_b, x2_b, y2_b):\n",
    "    task_losses = vmap(partial(maml_loss, p))(x1_b, y1_b, x2_b, y2_b)\n",
    "    return np.mean(task_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "d825f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need ethnic_grp_pop list which contains population of each ethinc group\n",
    "#training data is a list of arrays each of which corresponds to an ethinic groups \n",
    "#inner batch size < ethnic_grp_min_pop\n",
    "def sample_tasks(outer_batch_size, inner_batch_size):\n",
    "    # Select amplitude and phase for the task\n",
    "    ethnic_grp_sample=random.sample(eth, size=outer_batch_size)\n",
    "\n",
    "    def get_batch():\n",
    "        xs, ys = [], []\n",
    "        for j in ethnic_grp_sample:\n",
    "            indices = onp.random.randint(ethnic_grp_min_pop,size=inner_batch_size)\n",
    "            x= x_train.loc[j].iloc(indices).to_numpy()\n",
    "            y= y_train.loc[j].iloc(indices).to_numpy()\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        return np.stack(xs), np.stack(ys)\n",
    "    x1, y1 = get_batch()\n",
    "    x2, y2 = get_batch()\n",
    "    return x1, y1, x2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "eb75649c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1141/3982388584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#meta training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopt_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#meta training\n",
    "opt_init, opt_update = optimizers.adam(step_size=1e-3)\n",
    "out_shape, net_params = net_init(in_shape)\n",
    "opt_state = opt_init(net_params)\n",
    "\n",
    "# vmapped version of maml loss.\n",
    "# returns scalar for all tasks.\n",
    "def batch_maml_loss(p, x1_b, y1_b, x2_b, y2_b):\n",
    "    task_losses = vmap(partial(maml_loss, p))(x1_b, y1_b, x2_b, y2_b)\n",
    "    return np.mean(task_losses)\n",
    "\n",
    "@jit\n",
    "def step(i, opt_state, x1, y1, x2, y2):\n",
    "    p = optimizers.get_params(opt_state)\n",
    "    g = grad(batch_maml_loss)(p, x1, y1, x2, y2)\n",
    "    l = batch_maml_loss(p, x1, y1, x2, y2)\n",
    "    return opt_update(i, g, opt_state), l\n",
    "\n",
    "np_batched_maml_loss = []\n",
    "\n",
    "for i in range(20000):\n",
    "    x1_b, y1_b, x2_b, y2_b = sample_tasks(num_tasks_sample, batch_size)\n",
    "    opt_state, l = step(i, opt_state, x1_b, y1_b, x2_b, y2_b)\n",
    "    np_batched_maml_loss.append(l)\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "net_params = optimizers.get_params(opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "c82cb086",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_1141/3188372714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MXL'\u001b[0m \u001b[0;31m#the ethnic group we want to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#pre update prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpre_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpre_error\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#post-update prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "#meta test; train with K examples from validation set on desired task\n",
    "task='MXL' #the ethnic group we want to test\n",
    "#pre update prediction\n",
    "pre_predictions = vmap(partial(net_apply, net_params))(x_test[task])\n",
    "pre_error= loss(net_params,x_test[task],y_test[task])\n",
    "#post-update prediction\n",
    "indx=onp.random.randint(pop[task],batch_size)\n",
    "x1, y1 = x_train[task][indx] , y_train[task][indx]\n",
    "for i in range(K):\n",
    "    opt_state, l = inner_update(net_params,x1,y1)\n",
    "    \n",
    "   \n",
    "post_predictions = vmap(partial(net_apply, net_params))(x_test[task])\n",
    "post_error= loss(net_params,x_test[task],y_test[task])\n",
    "\n",
    "print('pre update MSE='+str())\n",
    "print('post update MSE='+str(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heterogeneous model: presence of phenotype if sum allele frequencies is greater than c\n",
    "#choose thresholds 1,2,3,4,5,6,7,8,9\n",
    "#choose causal snps (maybe first 5) \n",
    "# if the sum of the allele frequencies of these causal snps is greater than the threshold\n",
    "#then phenotype is 1 otherwise 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2efeca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86c32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('processed_data.csv',index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664bf6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=data2.apply(lambda x: sum(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ab885ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5=pd.read_csv('eth_ID.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e73e4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth=data5['eth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa784e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GBR', 'FIN', 'EAS', 'PUR', 'CLM', 'IBS', 'PEL', 'SAS', 'KHV',\n",
       "       'ACB', 'GWD', 'ESN', 'MSL', 'STU', 'EUR', 'YRI', 'JPT', 'LWK',\n",
       "       'ASW', 'MXL', 'TSI'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4ca366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_threshold=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b8ab26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_vec= np.random.randint(max_threshold,size=len(eth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8cafcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 10 random causal snps\n",
    "heteromodel_causal_snps=np.random.choice(data2.columns,size=10,replace=False)\n",
    "heteromodel_coef=[]\n",
    "heteromodel_thresh={}\n",
    "for i in data2.columns:\n",
    "    if i in heteromodel_causal_snps:\n",
    "        heteromodel_coef.append(1)\n",
    "    else:\n",
    "        heteromodel_coef.append(0)\n",
    "\n",
    "j=0\n",
    "for i in eth:\n",
    "    heteromodel_thresh[i]=threshold_vec[j]\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0544eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['51479', '55545', '77961', '84002', '87190', '275654', '631490',\n",
       "       '734210', '779968', '792275',\n",
       "       ...\n",
       "       '1325753', '1329159', '1331096', '1334949', '1337898', '1341079',\n",
       "       '1343267', '1346453', '1351587', '1353091'],\n",
       "      dtype='object', length=218)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1d2bd155",
   "metadata": {},
   "outputs": [],
   "source": [
    "heteromodel_causal_snps=np.random.choice(data2.columns,size=10,replace=False) #choose 10 causal snps from columns of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9475e543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1115619', '1160003', '1086657', '1173724', '836587', '981169',\n",
       "       '1118005', '1337898', '1196039', '1291869'], dtype=object)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heteromodel_causal_snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b8f8025d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>51479</th>\n",
       "      <th>55545</th>\n",
       "      <th>77961</th>\n",
       "      <th>84002</th>\n",
       "      <th>87190</th>\n",
       "      <th>275654</th>\n",
       "      <th>631490</th>\n",
       "      <th>734210</th>\n",
       "      <th>779968</th>\n",
       "      <th>792275</th>\n",
       "      <th>...</th>\n",
       "      <th>1325753</th>\n",
       "      <th>1329159</th>\n",
       "      <th>1331096</th>\n",
       "      <th>1334949</th>\n",
       "      <th>1337898</th>\n",
       "      <th>1341079</th>\n",
       "      <th>1343267</th>\n",
       "      <th>1346453</th>\n",
       "      <th>1351587</th>\n",
       "      <th>1353091</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eth</th>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">GBR</th>\n",
       "      <th>HG00096</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">SAS</th>\n",
       "      <th>NA21137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21141</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21142</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA21144</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             51479  55545  77961  84002  87190  275654  631490  734210  \\\n",
       "eth ID                                                                   \n",
       "GBR HG00096      1      0      0      1      0       0       0       0   \n",
       "    HG00097      0      0      0      0      0       2       0       0   \n",
       "    HG00099      0      2      0      0      0       0       0       0   \n",
       "    HG00100      0      0      0      1      0       0       0       0   \n",
       "    HG00101      0      1      1      0      1       0       0       0   \n",
       "...            ...    ...    ...    ...    ...     ...     ...     ...   \n",
       "SAS NA21137      0      0      0      0      0       0       0       0   \n",
       "    NA21141      1      0      0      1      0       0       0       0   \n",
       "    NA21142      0      0      0      0      0       1       0       0   \n",
       "    NA21143      0      0      0      1      0       1       0       0   \n",
       "    NA21144      0      2      1      0      2       1       0       0   \n",
       "\n",
       "             779968  792275  ...  1325753  1329159  1331096  1334949  1337898  \\\n",
       "eth ID                       ...                                                \n",
       "GBR HG00096       2       0  ...        1        2        2        2        1   \n",
       "    HG00097       2       0  ...        0        2        2        2        2   \n",
       "    HG00099       2       0  ...        0        2        2        2        2   \n",
       "    HG00100       2       0  ...        0        2        2        2        2   \n",
       "    HG00101       2       0  ...        0        2        2        2        2   \n",
       "...             ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "SAS NA21137       2       0  ...        0        2        2        2        2   \n",
       "    NA21141       2       0  ...        1        2        2        2        1   \n",
       "    NA21142       2       0  ...        0        2        2        2        2   \n",
       "    NA21143       2       0  ...        0        2        2        2        2   \n",
       "    NA21144       2       0  ...        1        2        2        2        2   \n",
       "\n",
       "             1341079  1343267  1346453  1351587  1353091  \n",
       "eth ID                                                    \n",
       "GBR HG00096        2        0        0        2        2  \n",
       "    HG00097        2        0        0        2        2  \n",
       "    HG00099        2        0        0        2        2  \n",
       "    HG00100        2        0        0        2        2  \n",
       "    HG00101        2        0        0        2        2  \n",
       "...              ...      ...      ...      ...      ...  \n",
       "SAS NA21137        2        0        0        2        2  \n",
       "    NA21141        2        0        0        2        2  \n",
       "    NA21142        2        0        0        2        2  \n",
       "    NA21143        2        0        0        2        2  \n",
       "    NA21144        2        0        0        2        2  \n",
       "\n",
       "[2503 rows x 218 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f9e996cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1115619',\n",
       " '1160003',\n",
       " '1086657',\n",
       " '1173724',\n",
       " '836587',\n",
       " '981169',\n",
       " '1118005',\n",
       " '1337898',\n",
       " '1196039',\n",
       " '1291869']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(heteromodel_causal_snps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9edfc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#phenotype\n",
    "data3=data2.apply(lambda x: 1 if x@heteromodel_coef>heteromodel_thresh[x.name[0]] else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7d0c2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20efe046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hetero_model(eth,x,max_threshold=20,num_heteromodel_causal_snps=10):\n",
    "    threshold_vec= np.random.randint(max_threshold,size=len(eth)) #random choice of thresholds as many as ethnicities\n",
    "    heteromodel_causal_snps=np.random.choice(x.columns,size=num_heteromodel_causal_snps,replace=False) #choose 10 causal snps from columns of x\n",
    "    heteromodel_coef=[] #array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh={} #dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps:\n",
    "            heteromodel_coef.append(1)\n",
    "        else:\n",
    "            heteromodel_coef.append(0)\n",
    "\n",
    "    j=0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh[i]=threshold_vec[j]\n",
    "        j = j + 1\n",
    "    \n",
    "    y=x.apply(lambda t: 1 if t@heteromodel_coef>heteromodel_thresh[t.name[0]] else 0,axis=1)\n",
    "    \n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "57492571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(eth,x):\n",
    "    #dictionary which contains randomly generated coeffiicnets for the linear model\n",
    "    eth_coef={}\n",
    "    eth_errors={}\n",
    "    eth_errors_sigma2=onp.random.randint(1,5, size=len(eth))\n",
    "    eth_errors.update([(ethnicity,errors/100) for ethnicity,errors in zip(eth,eth_errors_sigma2)])\n",
    "\n",
    "    for i in eth:\n",
    "        eth_coef[i]=onp.random.uniform(-1,1,(x.shape[1]))\n",
    "\n",
    "    y=x.apply(lambda a: a@eth_coef[a.name[0]]+onp.random.normal(scale=eth_errors[a.name[0]]),axis=1)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1a0e1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensatory_model(eth,x,max_threshold1=10,max_threshold2=5,num_heteromodel_causal_snps1=20,num_heteromodel_causal_snps2=50):\n",
    "    threshold_vec1= np.random.randint(max_threshold1,size=len(eth)) #random choice of thresholds as many as ethnicities\n",
    "    threshold_vec2= np.random.randint(max_threshold2,size=len(eth)) #random choice of thresholds as many as ethnicities\n",
    "   \n",
    "    heteromodel_causal_snps=np.random.choice(x.columns,size=num_heteromodel_causal_snps1+num_heteromodel_causal_snps2,replace=False) #choose 10 causal snps from columns of x\n",
    "    heteromodel_causal_snps1=heteromodel_causal_snps[0:num_heteromodel_causal_snps1]\n",
    "    heteromodel_causal_snps2=heteromodel_causal_snps[num_heteromodel_causal_snps1:-1]\n",
    "    heteromodel_coef1=[] #array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh1={} #dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps1:\n",
    "            heteromodel_coef1.append(1)\n",
    "        else:\n",
    "            heteromodel_coef1.append(0)\n",
    "\n",
    "    j=0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh1[i]=threshold_vec1[j]\n",
    "        j = j + 1\n",
    "    \n",
    "    heteromodel_coef2=[] #array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh2={} #dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps2:\n",
    "            heteromodel_coef2.append(1)\n",
    "        else:\n",
    "            heteromodel_coef2.append(0)\n",
    "\n",
    "    j=0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh2[i]=threshold_vec2[j]\n",
    "        j = j + 1\n",
    "    \n",
    "    y=x.apply(lambda t: 0 if (((t@heteromodel_coef1>heteromodel_thresh1[t.name[0]]) and\n",
    "              (t@heteromodel_coef2>heteromodel_thresh2[t.name[0]])) | \n",
    "                              ((t@heteromodel_coef1<=heteromodel_thresh1[t.name[0]]) and\n",
    "              (t@heteromodel_coef2<=heteromodel_thresh2[t.name[0]])))\n",
    "              else 1 ,axis=1)\n",
    "    \n",
    "    #return heteromodel_thresh1,heteromodel_thresh2,y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ee112635",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=compensatory_model(eth,data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6d0fd9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eth  ID     \n",
       "GBR  HG00096    0\n",
       "     HG00097    0\n",
       "     HG00099    0\n",
       "     HG00100    0\n",
       "     HG00101    0\n",
       "               ..\n",
       "SAS  NA21137    0\n",
       "     NA21141    0\n",
       "     NA21142    0\n",
       "     NA21143    0\n",
       "     NA21144    0\n",
       "Length: 2484, dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1[q1==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6e374fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3=hetero_model(eth,data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bc2317ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eth  ID     \n",
       "FIN  HG00171    1\n",
       "     HG00173    1\n",
       "     HG00174    1\n",
       "     HG00176    1\n",
       "     HG00177    1\n",
       "               ..\n",
       "TSI  NA20822    1\n",
       "     NA20826    1\n",
       "     NA20827    1\n",
       "     NA20828    1\n",
       "     NA20832    1\n",
       "Length: 653, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3[q3==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "45b6c2ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_threshold1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2k/t0wc7sg54bd13v7tr3h8cd8c0000gp/T/ipykernel_23063/739230647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthreshold_vec1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_threshold1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#random choice of thresholds as many as ethnicities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mthreshold_vec2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_threshold2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#random choice of thresholds as many as ethnicities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mheteromodel_causal_snps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heteromodel_causal_snps1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_heteromodel_causal_snps2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#choose 10 causal snps from columns of x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mheteromodel_causal_snps1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheteromodel_causal_snps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_heteromodel_causal_snps1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_threshold1' is not defined"
     ]
    }
   ],
   "source": [
    "    threshold_vec1= np.random.randint(max_threshold1,size=len(eth)) #random choice of thresholds as many as ethnicities\n",
    "    threshold_vec2= np.random.randint(max_threshold2,size=len(eth)) #random choice of thresholds as many as ethnicities\n",
    "   \n",
    "    heteromodel_causal_snps=np.random.choice(x.columns,size=num_heteromodel_causal_snps1+num_heteromodel_causal_snps2,replace=False) #choose 10 causal snps from columns of x\n",
    "    heteromodel_causal_snps1=heteromodel_causal_snps[0:num_heteromodel_causal_snps1]\n",
    "    heteromodel_causal_snps2=heteromodel_causal_snps[num_heteromodel_causal_snps1:-1]\n",
    "    heteromodel_coef1=[] #array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh1={} #dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps1:\n",
    "            heteromodel_coef1.append(1)\n",
    "        else:\n",
    "            heteromodel_coef1.append(0)\n",
    "\n",
    "    j=0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh1[i]=threshold_vec1[j]\n",
    "        j = j + 1\n",
    "    \n",
    "    heteromodel_coef2=[] #array of 0 or 1 depending on whether a particular column is causal snp or not\n",
    "    heteromodel_thresh2={} #dictionary of thresholds for each ethnicity\n",
    "    for i in x.columns:\n",
    "        if i in heteromodel_causal_snps2:\n",
    "            heteromodel_coef2.append(1)\n",
    "        else:\n",
    "            heteromodel_coef2.append(0)\n",
    "\n",
    "    j=0\n",
    "    for i in eth:\n",
    "        heteromodel_thresh2[i]=threshold_vec2[j]\n",
    "        j = j + 1\n",
    "    \n",
    "    y=x.apply(lambda t: 0 if (t@heteromodel_coef1>heteromodel_thresh1[t.name[0]] and\n",
    "              t@heteromodel_coef2>heteromodel_thresh2[t.name[0]] | \n",
    "                              t@heteromodel_coef1<=heteromodel_thresh1[t.name[0]] and\n",
    "              t@heteromodel_coef2<=heteromodel_thresh2[t.name[0]])\n",
    "              else 1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffe9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
